{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93iGB2PMDiaa"
   },
   "source": [
    "# Introducing the Naive Bayes Classifier\n",
    "\n",
    "Now we will use annotated data to \"learn\" a sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-sX590NpDiab"
   },
   "outputs": [],
   "source": [
    "# We first install the new dependency: nlpia (03_dit_coli_naivebayes.ipynb)\n",
    "\n",
    "# ! pip3 install nlpia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8ZXWCunDiad"
   },
   "outputs": [],
   "source": [
    "# Loading the dependencies\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# from nlpia.data.loaders import get_data \n",
    "\n",
    "# The casual tokenizer can handle emoticons, unusual punctuation and slang better than the TreeBank tokenizer\n",
    "from nltk.tokenize import casual_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEEXu6s3Diae"
   },
   "source": [
    "## Setting up the _corpus_\n",
    "\n",
    "\n",
    "Loading the movies corpus from Hutto movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MksGSDODiaf"
   },
   "outputs": [],
   "source": [
    "# This was the original call to download the dataset, which requires the dependency from nlpia\n",
    "# movies = get_data('hutto_movies')\n",
    "\n",
    "# In this way, I am downloading the dataset directly from their own repository\n",
    "url=\"https://raw.githubusercontent.com/totalgood/nlpia/master/src/nlpia/data/hutto_ICWSM_2014/tweets_GroundTruth.csv\"\n",
    "\n",
    "movies=pd.read_csv(url)\n",
    "\n",
    "# Looking at some of the first instances\n",
    "movies.head().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvTU4XVmDiag"
   },
   "source": [
    "### Getting a description of the data (look at the range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxQnvm9lDiah"
   },
   "outputs": [],
   "source": [
    "movies.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCo9AMhLDiah"
   },
   "outputs": [],
   "source": [
    "# Helps display wide DataFrames in the console, so they look prettier\n",
    "pd.set_option('display.width', 75)\n",
    "movies.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1BsQK-4Diai"
   },
   "source": [
    "### Loading the data into a BoW DataFrame through a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpeFR1i6Diaj"
   },
   "outputs": [],
   "source": [
    "bags_of_words = []\n",
    "\n",
    "for text in movies.text:\n",
    "    bags_of_words.append(Counter(casual_tokenize(text)))\n",
    "\n",
    "df_bows = pd.DataFrame.from_records(bags_of_words)\n",
    "\n",
    "# from_records() is a DataFrame constructor.\n",
    "# INPUT: a sequence (list) of dictionaries\n",
    "# OUTPUT: a DF with columns for all the keys and associated values. \n",
    "# (Missing values become NaN!)\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cU1Hv7K1Diak"
   },
   "outputs": [],
   "source": [
    "# So we fill them with 0:\n",
    "df_bows = df_bows.fillna(0).astype(int)\n",
    "print(df_bows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uX3jwWktDian"
   },
   "source": [
    "### Let us look at the shape\n",
    "\n",
    "**Spoiler**: A BoW can explode in size; even more when no normalisation is applied at all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKu4rVYyDian"
   },
   "outputs": [],
   "source": [
    "df_bows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O54rsOArDiao"
   },
   "source": [
    "Now, let us see the first instances (it is quite sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nu9n3UHGDiao"
   },
   "outputs": [],
   "source": [
    "df_bows.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Awaj-M-oDiap"
   },
   "source": [
    "\n",
    "**Homework**: Integrate the normalisation pipeline (lowercasing, stopwording and stemming or lemmatisation) and see how the dataframe gets affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUBDqzFLDiap"
   },
   "outputs": [],
   "source": [
    "# write your code here\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6VMVsj9dDiaq"
   },
   "outputs": [],
   "source": [
    "print(df_bows.head()[list(bags_of_words[0].keys())])\n",
    "print(df_bows.head()[list(bags_of_words[1].keys())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ATeewTDDiaq"
   },
   "source": [
    "### Build the Nave Bayes' classifier\n",
    "\n",
    "All the data is now ready. Let us build a Multinomial NB.\n",
    "\n",
    "Multinomial NB is suitable for discrete features (e.g., word counts for text classification). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z27VwyjsDiaq"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DhWrv5S3Diar"
   },
   "outputs": [],
   "source": [
    "# \"Binarising\" the classes\n",
    "movies.sentiment > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwQ_hZEmDiar"
   },
   "source": [
    "Now we can train (\"fit\") our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DkaG5fTdDiar"
   },
   "outputs": [],
   "source": [
    "# We are converting the class from float to Boolean, \n",
    "# as this classifier only supports discrete labels \n",
    "nb = nb.fit(df_bows, movies.sentiment > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtOrrSqADiar"
   },
   "source": [
    "### We have a model and we can predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmdvwdQoDias"
   },
   "outputs": [],
   "source": [
    "# predict_proba() gets continious-value predictions.\n",
    "# We multiply and subtract it to convert the output to range [-4,4]\n",
    "\n",
    "#print(predictions[:10])\n",
    "# TODO there seems to be an error in th ebook code. \n",
    "# predict_proba returns the scores for all the classes (2) and we aim at\n",
    "# assigning only the one for the positive class. \n",
    "# I had to to the following trick instead of the original\n",
    "# movies['predicted_sentiment'] = nb.predict(df_bows) * 8 - 4\n",
    "predictions = nb.predict_proba(df_bows) * 8 - 4 \n",
    "movies['predicted_sentiment'] = [x[1] for x in predictions]\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Js3TVM6sDiat"
   },
   "source": [
    "Now, we compute the [Mean Absolut Error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) \"a measure of difference between two continuous variables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZEBytu4Diat",
    "outputId": "a049fecc-171a-407e-c62f-98061f93fd35"
   },
   "outputs": [],
   "source": [
    "movies['error'] = (movies.predicted_sentiment - movies.sentiment).abs()\n",
    "# This is the mean absolute error (MAE)\n",
    "round(movies.error.mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYADj2RAEz0L"
   },
   "outputs": [],
   "source": [
    "# abs(n)\n",
    "\n",
    "# abs(5) -> 5\n",
    "# abs(-34) -> 34\n",
    "# abs(0) -> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrXXp1ozDiau"
   },
   "source": [
    "Now, let us see some gold and predicted sentiments, together with the binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PALMjqNSDiau"
   },
   "outputs": [],
   "source": [
    "# Gold standard is positive\n",
    "movies['sentiment_ispositive'] = (movies.sentiment > 0).astype(int)\n",
    "\n",
    "# Prediction is positive\n",
    "movies['predicted_ispositive'] = (movies.predicted_sentiment > 0).astype(int)\n",
    "\n",
    "# Let us have an overview of gold standard vs prediction\n",
    "movies['''sentiment predicted_sentiment sentiment_ispositive predicted_ispositive'''.split()].head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xr05Vwv6Diau"
   },
   "outputs": [],
   "source": [
    "# And this is the percentage of \"thumbs up\" rating correctly predicted    \n",
    "(movies.predicted_ispositive == movies.sentiment_ispositive).sum() / len(movies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW9yBVYqDiav"
   },
   "source": [
    "## not bad at all!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "04_dit_coli_naivebayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
