{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting the tokens from a corpus\n",
    "\n",
    "This jupyter notebook is intended for lesson 3 of DIT's Natural Language Processing course\n",
    "\n",
    "We are going to setup a toy corpus and compute some _similarities_.\n",
    "\n",
    "The libraries to be used today are:\n",
    "\n",
    "* [numpy](https://numpy.org/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [nltk](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Prerequisites\n",
    "\n",
    "Since we are going to use non-standard libraries, we need to set them up --if working on an ephemeral environment (e.g., colab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setting up the _corpus_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "stemmer = PorterStemmer() \n",
    "\n",
    "sentences = \"\"\"Thomas Jefferson began building Monticello at the age of 26.\\n\"\"\"\n",
    "sentences += \"\"\"Construction was done mostly by local masons and carpenters.\\n\"\"\"\n",
    "sentences += \"He moved into the South Pavilion in 1770.\\n\"\n",
    "sentences += \"\"\"Turning Monticello into a neoclassical masterpiece was Jefferson's obsession.\"\"\"\n",
    "\n",
    "sentence = sentences.lower()\n",
    "sentence      # what is the diff wrt print()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bag-of-words representation\n",
    "\n",
    "Let us compute the BoW representation for our toy corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the corpus into a dictionary\n",
    "corpus ={}\n",
    "for i, sent in enumerate(sentences.split('\\n')):\n",
    "    sentence = sent.lower()                 # Case folding\n",
    "    tokens = tokenizer.tokenize(sentence)   # Tokenisation \n",
    "    stems = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    corpus['sent{}'.format(i)] = dict((tok, 1) for tok in\n",
    "         stems)\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data into a pandas dataframe\n",
    "df = pd.DataFrame.from_records(corpus).fillna(0).astype(int).T\n",
    "\n",
    "# df[df.columns[:10]]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computing the dot product\n",
    "\n",
    "\"The sum of the products of the corresponding entries of two sequences of numbers\". \n",
    "\n",
    "Let us go and have a look at the [Wikipedia](https://en.wikipedia.org/wiki/Dot_product).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "v1 = np.array([1, 2, 3])\n",
    "v2 = np.array([2, 4, 6])\n",
    "\n",
    "\n",
    "# The long way\n",
    "sum_dot = 0\n",
    "\n",
    "for i in range(len(v1)):\n",
    "    sum_dot += v1[i] * v2[i]\n",
    "    print(\"result at iteration {}: {}\".format(i, sum_dot))\n",
    "print(\"Result:\", sum_dot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The smart way (we are \"vectorising\")\n",
    "dot = (v1 * v2).sum()\n",
    "print(dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numpy way\n",
    "v1.dot(v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product can be used to measure the overlap between two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to compute the transpose of the matrix \n",
    "# because I need column vectors\n",
    "\n",
    "# What is the transpose of a matrix??\n",
    "\n",
    "df = df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How can I print it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sent0.dot(df.sent1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sent0.dot(df.sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sent0.dot(df.sent3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do these numbers come from?\n",
    "print(sentences)\n",
    "[(k, v) for (k, v) in (df.sent0 & df.sent3).items() if v]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is your first **vector space model**!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "1. Implement the pre-processing pipeline with spacy.\n",
    "2. Apply stopwording as part of the pre-processing. \n",
    "\n",
    "**Questions**\n",
    "\n",
    "1. Stopwording should be done before or after casefolding / stemming (or lemmatisation)?\n",
    "2. Can I have a negative dot product?\n",
    "3. What is the meaning of a dot product = 0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
